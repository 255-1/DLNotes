+ ## [深度学习推荐系统](https://book.douban.com/subject/35013197/)  
### ***第二章 前深度学习时代***  

| 模型名称 | 基本原理 | 特点 | 局限性 |
|---|---|---|---|
|协同过滤|根据用户的行为历史生成用户-物品共现矩阵，利用用户相似性和物品相似性进行推荐|原理简单，直接，应用广泛|泛化能力差，处理稀疏矩阵能力差，推荐结果的头部效应明细那|
|矩阵分解|将协同过滤算法中的共现矩阵分解为用户矩阵和物品矩阵，利用用户隐向量和物品隐向量的内积进行排序并推荐|泛化能力有所加强，对稀疏矩阵的处理能力有所加强|除了用户历史行为数据，难以利用其他用户物品特征及上下文特征|
|逻辑回归|将推荐系统转换为CTR预估的二分类问题，将用户，物品，上下文等不用特征转换成特征向量，按照预估CTR进行排序并推荐|能融合多种类型的不同特征|模型不具备特征组合能力，表达能力较差|
|FM（Factorization Machine因子分解机）|在模型中加入二阶特征交叉部分，为每一维特诊训练得到相应特诊隐向量，通过隐向量间的内积运算得到交叉特征权重|比起逻辑回归具备了二阶特征交叉能力，模型表达能力增强|组合爆炸问题，模型不易扩展到三阶特征交叉|
|FFM（Field-aware Factorization Machine域感知因子分解机）|在FM基础上加入特征域的概念，使每个特征在不同特征域交叉时采用不同的隐向量|进一步加强特征交叉能力|模型开销较大$ O(n^2) $|
|GBDT（梯度提升决策树）-LR|利用GBDT自动化特征组合,将原始特征向量转换成离散型特征向量,并输入逻辑回归模型|特征工程模型化,是模型具备了高阶特征组合的能力|GBDT无法并行训练，GDBT容易产生过拟合，而且丢失了大量特征的数值信息|
|LS-PLM|首先对样本进行分片,在每个分片内部构造逻辑回归模型,将每个样本的各个分片概率与逻辑回归的得分进行加权平均|模型结构类似三层神经网络,具备较强的表达能力，完成了端到端的非线性训练，模型的稀疏性较强|模型相比深度学习模型仍然比较简单|  

![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081301947.png)
**备注**: 用户数往往大于物品数,UserCF有更强的社交属性适合新闻推荐,ItemCF适用于兴趣稳定的视频推荐。矩阵论中定义向量之间的距离为向量的内积，第二章的一些机器学习算法中会使用内积衡量不同的向量，而内积结果越低，代表两个向量相近，更加相似所以可以用来推荐。使用L1范数比L2范数更加容易产生稀疏解。   
**个人总结**: 第二章主要讲述了机器学习算法在推荐系统中的应用,为了解决一系列的问题(如泛化能力差,处理稀疏矩阵,无法融合其他特征,特征无法组合,特征组合爆炸等)提出了一系列的解决办法,其中重点讲述了特征交叉的问题,认为特征首先不需要人手动处理而是需要模型化,其次特征需要相互组合得到特征之间的关系才能有比较好的结果。  

### ***第三章 深度学习在推荐系统中应用***  

| 模型名称 | 基本原理 | 特点 | 局限性 |  
|---|---|---|---|  
|AutoRec|基于自编码器，对用户或者物品进行编码，利用自编码器的泛化能力进行推荐|单隐层神经网络结构简单，可实现快速训练和部署|表达能力差|
|Deep Crossing|利用Embedding+多隐层+输出层的经典深度学习框架，预完成特征的自动深度交叉|经典深度学习推荐系统模型框架|利用全连接隐层进行特征交叉，针对性不强|
|NeuralCF|将传统的矩阵分解技术中的用户向量和物品向量的点积操作换成由神经网络代替的互操作|表达能力加强的矩阵分解模型|只使用了用户和物品的id特征，没有加入其他更多特征|
|PNN|针对不同的特征域之间的交叉操作，定义内积和外积等多种操作加入了乘积层|在经典深度学习框架之上提高特征交叉能力|外积操作做了近似化，影响表达能力|
|Wide&Deep|利用Wide加强模型的记忆能力，利用Deep部分加强模型的泛化能力|开创了组合模型的构造方法|Wide部分需要人工进行特征组合筛选|
|Deep&Cross|用Cross网络代替Wide部分|解决了人工特征组合问题|Cross网络复杂度高|
|FNN|利用FM的参数来初始化Embedding的初始化权重（FM用在Embedding前）|加速了网络的收敛速度|主结构简单没有针对性的特征交叉层|
|DeepFM|用FM代替原本的Wide部分（FM用在Embedding后）|加强了Wide部分的特征交叉能力|与Wide&Deep差别不明显|
|NFM|用神经网络替代FM中的二阶隐向量交叉操作（FM用在Embedding之后），相当于Wide&Deep中的Deep加入特征交叉池化层|相比FM加强了表达能力|以PNN结构相似|
|AFM|在FM基础上加入注意力得分机制，并使用注意力网络学习注意力得分|不同交叉特征的重要性不同|训练过程复杂|
|DIN|在传统的深度学习推荐模型的基础上引入注意力机制，并利用用户行为历史物品和目标广告物品的相关性计算注意力得分|根据目标广告物品的不同有更准确的推送|没有充分利用除了历史行为意外的其他特征|
|DIEN|将序列模型与深度学习推荐模型结合，使用序列模型模拟用户的兴趣进化过程|序列模型增强了系统对用户兴趣变迁的表达能力，考虑了时间相关的行为序列中包含的有价值的信息|训练复杂，线上服务延迟较长，需要进行工程上的优化|
|DRN|将强化学习的思路应用于推荐系统，尽心推荐模型的线上实时学习与更新|模型对数据实时性的利用能力大大增强|线上部分较复杂，工程实现难度较大|   

![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081302310.png)

**备注**: “记忆能力”可以理解成模型直接学习并利用历史数据中武平或者特征的能力，“泛化能力”可以理解成模型传递特征的相关性，遗迹发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。Deep Crossing可以完成端到端的训练。注意力机制在数学形式上只是将过去的平均操纵或者加和操作换成了加权和或者加权平均操作。Embedding收敛很慢（FNN尝试解决）。注意力机制的轻重应该由同类信息的相关性决定。    
**个人总结**:第三章讲解了许多深度学习的推荐系统模型，每个模型都有很多相似的地方，一些深度学习模型也改进了过去机器学习算法的局限性。在前几个网络还在解决特征交叉这个机器学习算法也在致力于解决的问题，后面进一步升级引入了注意力机制，不仅让特征交叉还给予他们不同的权重。其次深度学习的发展，让引入一些例如序列信息成为现实。   

### ***第四章 Embedding技术再推荐系统中的应用***  

| Embedding技术 | 基本原理 | 特点 | 局限性 |  
|---|---|---|---|  
|Word2vec|利用句子中次的相关性建模，利用单隐层神经网络获得词的Embedding向量|经典Embedding方法|仅能针对词序列样本进行训练|
|Item2vec|把Word2vec的思想推广到任何序列数据上|将Word2vec应用于推荐系统|仅能针对序列样本进行训练|
|DeepWalk|在图结构上随机游走，生成序列样本后利用Word2vec方法建模|易用的Graph Embedding方法|随机游走进行抽样的针对性不强|
|Node2vec|在DeepWalk的基础上，通过调整随机游走权重的方法使Graph Embedding的结果在网络的同质性和结构性之间进行权衡|可以针对性地挖掘不同的网络特征|需要比较多的人工调参工作|
|EGES|将不同信息对应的Embedding加权融合后生成的最终的Embedding向量|融合多种补充信息,解决Embedding冷启动问题|没有较大的学术创新，更多是从工程角度|
|局部敏感哈希|利用局部敏感哈希的原理进行快速Embedding向量最近邻搜索|解决利用Embedding作为召回层的快速计算问题|存在小概率的最近邻遗漏可能，需要人工调参|  

**备注**: 形式上讲Embedding就是用一个低维稠密的向量表示一个对象。物品Embedding可以直接获得。在欧氏空间中，将高维空间的点映射到低维空间，原本相近的点在低维空间依然相近，但原本远离的点则有一定概率变成相近的点。局部哈希可以使用不同的距离标准，如余弦相似度，曼哈顿距离，切比雪夫距离，汉明距离。   
**个人总结**:第四章讲解了Embedding技术迭代优化的过程，现在主要研究对象是图结构，如同深度学习模型中现在加入了Attention注意力机制一样，在Embedding中也加入了加权融合的想法， Node2vec这种对网络两种性质的探索我个人感觉十分新颖。    

### ***第五章 多角度审视推荐系统***   

>如何选取和处理特征:  

1.用户行为数据。包含显性与隐性，处理方式一种是将代表用户的物品id序列转换成multi-hot，另一种是预先训练好物品的Embedding    
2.用户关系数据。强关系（关注，好友），弱关系（点赞，同一社区） ，处理方式使用Graph Embedding   
3.属性、标签类数据。人口属性数据，给对象打上标签，处理方式通过multi-hot，重要的属性标签可以转换成Embedding  
4.内容类数据。一般无法直接使用（文字，视频），需要抽取特征   
5.上下文信息。时间，GPS，假日等。
6.统计类特征。通过统计计算得到的数据，历史CTR，CVR，物品热门程度（比较重要）  
7.组合类特征。年龄+性别，可以交给模型自动处理  

特征总特分为连续性特征和离散型特征，连续性特征常用手段有归一化，离散化，加非线性函数，离散化的主要目的是防止连续值带来的过拟合现象及特征值不均匀，加非线性函数（$ x^a $, $ log_a(x)$, $ log(x/1-x)$）为了更好的捕获特征与优化目标之间的非线性关系，增强非线性表达能力。**特征工程需要多多思考业务**

>召回层的主要策略  

1.多路召回策略。对ki个策略召回Topki到排序层，缺陷是候选集大小以及策略之间相互割裂   

![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081302871.png)

2.基于Embedding的召回方法。

>实时性的重要性及提高方法  

模型更新间隔时间越长没推荐系统的效果越差，（1）推荐系统更新速度越快，代表用的最新习惯和爱好特征更新越快，越能为用户进行有时效性的推荐，（2）推荐系统更新越快，越容易发现最新流行的数据模式，更快抓住最新的流行趋势。**特征的实时性为了更准确地描述用户、物品和相关信息，让推荐系统给出符合当时场景的推荐结果。而模型的实时性则是希望更快地抓住全局层面的新数据模式，发现新的趋势和相关性。**   
1.特征实时性  
特征实时性的三个主要阶段是客户端实时特征（session内部进行实时推荐），流计算平台的实时特征处理，分布式批处理平台的全量特征处理（主要用于模型训练和离线评估，更新特征数据库）  
2.模型实时性  
模型是实时性分为全量更新，增量更新，在线学习

![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081302952.png)

>合理设定优化目标  

youtube观看时长为优化目标的合理性，阿里巴巴的ESMM的例子

>基于用户动机改进模型结构    

大公司的模型不是银弹，要从应用场景出发，基于用户行为和数据特点，提出合理的改进模型的动机才是最重要的，真正的银弹是你对用户行为和应用场景的观察的思考

>冷启动解决办法     

冷启动问题根据数据的匮乏情况的不同分为三类。  
（1）用户冷启动，新用户没有历史数据  
（2）物品冷启动，新物品没有交互记录  
（3）系统冷启动，推荐系统之初缺乏所有相关数据  
主流的解决办法有  
（1）基于规则的冷启动过程。可以让系统回退到“前推荐系统时代”，使用热门排行榜，最近流行趋势，最高评分等榜单作为默认的推荐列表，这依赖于领域专家对业务的观察，需要充分了解公司的业务特点，充分利用已有数据，而且与推荐系统的主模型割裂。  
（2）丰富冷启动过程中可获得的用户和物品特征。在模型中加入更多用户或者物品特征，而非历史数据特征。用户注册信息，第三方DMP，物品内容特征（标签，分类，描述文字），引导用户输入（第一次登陆选择）    
（3）利用主动学习、迁移学习和“探索与利用”机制  
主动学习原理与强化学习原理一脉相承。迁移学习，如果模型结构和特征工程相同的前提下，可以将原来模型的参数作为初始值。探索与利用需要找寻平衡达到推荐系统的商业目标，探索与利用机制可以更好的挖掘用户的潜在兴趣，维持系统的长期受益状态。

>**探索与利用**  

（1）传统的探索与利用。多臂老虎机问题，e-Greedy算法，Thompson Sampling 和UCB，无法解决因如果个性化特征的问题    

![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081303825.png)  

（2）个性化的探索与利用。用户冷启动情况下，即使物品被充分探索，对于新用户依旧陌生，用户态度未知。所以需要解决基于上下文的多臂老虎机算法，LinUCB，局限于推荐系统是线性模型  
（3）基于模型的探索与利用。类似DRN中每次对参数进行的随机扰动$ \triangle W$  
探索与利用机制在推荐系统中场景多样。  
（1）物品冷启动。探索与利用算法对新物品和长尾物品有天然的倾向性    
（2）发觉用户新兴趣。    
（3）增加结果多样性。 

**备注**: CTR场景和投硬币都可以看作伯努利过程。   
**个人总结**:第五章讲解了一系列除了模型以外还需要处理的问题，特征，召回层，实时性，优化目标，冷启动问题总体来说就是要站在应用场景中改进模型，作者没有介绍排序层的内容。  


### ***第七章 推荐系统的评估***  

>离线评估的方法和指标   

主要方法有，（1）Holdout检验，交叉检验，自助法（样本规模小）
指标，（1）准确率，（2）精确率和召回率，精确率是分类正确的正样本个数比判定为正样本总数的比例，召回率是分类正确的正样本数比真正样本总数的比例，（3）均方根误差，（4）对数损失函数

>离线仿真评估方法Replay  

（1）P-R曲线，（2）ROC曲线，（3）平均精度均值，（4）归一化折扣累计收益，（5）覆盖率，（6）多样性，etc  
Replay根据时间依次预测，适用于几乎所有推荐系统的离线评估，而且是强化学习类模型的唯一离线评估方法，重点是样本不能包含任何的未来信息。
离线评估无法消除数据有偏现象，无法完全还原线上的工程环境，某些商业指标在离线评估中无法计算。

>线上A/B测试方法和线上评估指标   

最重要的指标，上线前的最后一步测试，基本原则，（1）层与层之间的流量正交，（2）同层之间的流量互斥
![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081303057.png)

|推荐系统类别|线上A/B测试评估指标|
|---|---|
|电商类|CTR，CVR，客单价（用户平均消费金额）|
|新闻类|留存率，平均停留时长，平均点击个数|
|视频类|播放完成率，平均播放时长，播放总时长|

有统计学上缺陷，分组中重度用户如果分配不均匀就会有很大的偏差

>Interleaving  

不区分A/B组，把不同的被测对象给受试者
![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081303046.png)
Interleaving能够利用小样本快速评估算法（100倍)，和A/B结果相关性比较大，A/B测试依旧是最权威的指标，因为Interleaving展示的是混合的结果，数据不准确，工程实现复杂


推荐系统的评估体系  
![](https://paperrecord.oss-cn-shanghai.aliyuncs.com/202204081303027.png)

**备注**:    
**个人总结**: 第七章讲解了一系列的推荐系统在线的或者离线的评估指标，感觉了解，会用就行    

